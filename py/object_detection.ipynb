{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import YolosFeatureExtractor, YolosForObjectDetection\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"data\", \"coco_classes.txt\"), \"r\") as f:\n",
    "    coco_classes = [c.rstrip(\"\\n\") for c in f.readlines()]\n",
    "coco_classes.insert(0, \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coco_classes))\n",
    "print(coco_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = YolosFeatureExtractor.from_pretrained(\"hustvl/yolos-small\")\n",
    "model = YolosForObjectDetection.from_pretrained(\"hustvl/yolos-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "\n",
    "thumbnail_dir = os.path.join(\"..\", \"data\", \"thumbnails\")\n",
    "img_names = os.listdir(thumbnail_dir)\n",
    "for img_name in img_names:\n",
    "    img_path = os.path.join(thumbnail_dir, img_name)\n",
    "    all_images.append(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = all_images[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[-3])\n",
    "print(np.array(images[-3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# model predicts bounding boxes and corresponding COCO classes\n",
    "logits = outputs.logits\n",
    "bboxes = outputs.pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.keys())\n",
    "print(inputs[\"pixel_values\"].shape)\n",
    "print(logits.shape)\n",
    "print(bboxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(logits.detach().clone(), dim=-1) # [B, 100, 92]\n",
    "preds      = probs.argmax(-1) # [B, 100]\n",
    "confidence = probs.max(-1)[0] # [B, 100]\n",
    "known_indices     = [(preds_img != 91).nonzero()[:,0] for preds_img in preds] # [B, known indices]\n",
    "confident_indices = [(conf_img > 0.75).nonzero()[:,0] for conf_img in confidence] # [B, confident indices]\n",
    "indices = [list(set(known_idx_img.tolist()).intersection(set(conf_idx_img.tolist()))) for known_idx_img,conf_idx_img in zip(known_indices, confident_indices)] # [B, intersection of indices]\n",
    "pred_classes = [[coco_classes[v] for v in preds_img[idx_img]] for preds_img, idx_img in zip(preds, indices)] # [B, predicted classes]\n",
    "\n",
    "confidence = (confidence*100).tolist()\n",
    "\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = len(images)\n",
    "fig, ax = plt.subplots(amount,1, figsize=(15,amount*13))\n",
    "\n",
    "pred_boxes = bboxes.detach().clone()\n",
    "cmap = plt.cm.get_cmap(\"hsv\", len(coco_classes))\n",
    "\n",
    "for img_idx, image in enumerate(images):\n",
    "    a = ax[img_idx]\n",
    "    a.imshow(image)\n",
    "    a.axis(\"Off\")\n",
    "\n",
    "    box_counter = 0\n",
    "    for j, patch_idx in enumerate(indices[img_idx]):\n",
    "        c = pred_classes[img_idx][j]\n",
    "        \n",
    "        conf = confidence[img_idx][patch_idx]\n",
    "        bbox = pred_boxes[img_idx, patch_idx].detach()\n",
    "        x, y, W, H = bbox.split(1)\n",
    "        im_w = image.width\n",
    "        im_h = image.height\n",
    "        W *= im_w\n",
    "        H *= im_h\n",
    "        x = x*im_w - W*.5\n",
    "        y = y*im_h - H*.5\n",
    "\n",
    "        a.text(x, y, f\"{c} ({conf:.2f}%)\", fontsize=20, c=\"white\")\n",
    "\n",
    "        # Create a Rectangle patch\n",
    "        color = cmap(preds[img_idx][patch_idx].item())\n",
    "        # color = \"b\"\n",
    "        rect = patches.Rectangle((x, y), W, H, linewidth=2,\n",
    "            edgecolor=color,\n",
    "            facecolor='none',\n",
    "        )\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        a.add_patch(rect)\n",
    "        box_counter += 1\n",
    "    print(\"box count: \", box_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
