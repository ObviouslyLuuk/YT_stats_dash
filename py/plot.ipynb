{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"data\", \"channels_info.json\"), \"r\") as f:\n",
    "    channels_info = json.load(f)\n",
    "channels = [c for c,dic in channels_info.items() if dic[\"Country\"] in [\"united-states\", \"united-kingdom\", \"australia\", \"netherlands\"]]\n",
    "print(len(channels))\n",
    "# channels_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"data\", \"videos_info.json\"), \"r\") as f:\n",
    "    videos_info_per_channel = json.load(f)\n",
    "for c in videos_info_per_channel:\n",
    "    for i in range(len(videos_info_per_channel[c])):\n",
    "        vid = videos_info_per_channel[c][i]\n",
    "        videos_info_per_channel[c][i][\"views_per_sub\"] = vid[\"views\"] / channels_info[c][\"Subscribers\"]\n",
    "        videos_info_per_channel[c][i][\"relative_views_30\"] = vid[\"views\"] / np.mean([v[\"views\"] for v in videos_info_per_channel[c]])\n",
    "        videos_info_per_channel[c][i][\"relative_views_to_max_30\"] = vid[\"views\"] / np.max([v[\"views\"] for v in videos_info_per_channel[c]])\n",
    "        videos_info_per_channel[c][i][\"relative_views_to_min_30\"] = vid[\"views\"] / np.min([v[\"views\"] for v in videos_info_per_channel[c]])\n",
    "        # videos_info_per_channel[c][i][\"relative_views_total\"] = vid[\"views\"] / channels_info[c][\"Video views\"]\n",
    "channels = list(set(videos_info_per_channel.keys()).intersection(channels))\n",
    "videos_info = [video_info for c in channels for video_info in videos_info_per_channel[c]]\n",
    "titles = [video_info[\"title\"] for video_info in videos_info]\n",
    "print(len(videos_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "title_encodings = sbert_model.encode(titles)\n",
    "title_to_vec = {k:v for k,v in zip(titles, title_encodings)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(title_encodings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate((title_encodings, np.array([video_info[\"views\"] for video_info in videos_info]).reshape(-1,1)), axis=-1)\n",
    "unit_title_encodings = StandardScaler().fit_transform(title_encodings)\n",
    "\n",
    "reducer_type = \"UMAP\"\n",
    "\n",
    "if reducer_type == \"PCA\":\n",
    "    # XY\n",
    "    pca = PCA(n_components=2)\n",
    "    title_XY = pca.fit_transform(unit_title_encodings)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.singular_values_)\n",
    "    # XYZ\n",
    "    pca = PCA(n_components=3)\n",
    "    title_XYZ = pca.fit_transform(unit_title_encodings)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.singular_values_)\n",
    "elif reducer_type == \"UMAP\":\n",
    "    min_dist, n_neighbors = .0001, 15\n",
    "    reducer = umap.UMAP(min_dist=min_dist, n_components=2, n_neighbors=n_neighbors, verbose=True)\n",
    "    reducer.fit(unit_title_encodings)\n",
    "    title_XY = reducer.transform(unit_title_encodings)\n",
    "    reducer = umap.UMAP(min_dist=min_dist, n_components=3, n_neighbors=n_neighbors, verbose=True)\n",
    "    reducer.fit(unit_title_encodings)\n",
    "    title_XYZ = reducer.transform(unit_title_encodings)\n",
    "\n",
    "title_to_xy = {k:v for k,v in zip(titles, title_XY)}\n",
    "title_to_xyz = {k:v for k,v in zip(titles, title_XYZ)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "X = [title_to_xy[title][0] for title in titles]\n",
    "Y = [title_to_xy[title][1] for title in titles]\n",
    "c = [np.log(dic[\"views\"]) for dic in videos_info]\n",
    "s = [np.sqrt(dic[\"views\"])/100 for dic in videos_info]\n",
    "\n",
    "# c = [np.log(dic[\"relative_views_30\"]) for dic in videos_info]\n",
    "# s = [np.sqrt(dic[\"relative_views_30\"])*50 for dic in videos_info]\n",
    "\n",
    "# c = [np.log(dic[\"relative_views_to_max_30\"]) for dic in videos_info]\n",
    "# s = [np.sqrt(dic[\"relative_views_to_max_30\"])*100 for dic in videos_info]\n",
    "\n",
    "# c = [np.log(dic[\"relative_views_to_min_30\"]) for dic in videos_info]\n",
    "# s = [np.sqrt(dic[\"relative_views_to_min_30\"])*10 for dic in videos_info]\n",
    "\n",
    "# c = [np.log(dic[\"views_per_sub\"]) for dic in videos_info]\n",
    "# s = [np.sqrt(dic[\"views_per_sub\"])*100 for dic in videos_info]\n",
    "\n",
    "indices = np.random.randint(0, len(X), (0))\n",
    "# indices = np.arange(30)\n",
    "\n",
    "for i in indices:\n",
    "    ax.text(X[i], Y[i], list(titles)[i], fontsize=7)\n",
    "\n",
    "mappable = ax.scatter(X, Y, c=c, s=s, alpha=.5,\n",
    "    # vmin=-1.5, vmax=1.5,\n",
    "    # vmin=-2, vmax=0,\n",
    "    # vmin=0, vmax=3,\n",
    ")\n",
    "ax.axis(\"Off\")\n",
    "\n",
    "# plt.colorbar(mappable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,5), subplot_kw=dict(projection='3d'))\n",
    "\n",
    "X = np.array([title_to_xyz[title][0] for title in titles])\n",
    "Y = np.array([title_to_xyz[title][1] for title in titles])\n",
    "Z = np.array([title_to_xyz[title][2] for title in titles])\n",
    "# Z = np.array([np.log(dic[\"views\"]) for dic in videos_info])\n",
    "c = np.array([np.log(dic[\"views\"]) for dic in videos_info])\n",
    "s = np.array([np.sqrt(dic[\"views\"])/100 for dic in videos_info])\n",
    "# s = 10\n",
    "# c = [dic[\"views\"] for dic in videos_info]\n",
    "\n",
    "# indices = np.random.randint(0, len(X), (20))\n",
    "# print(indices)\n",
    "indices = np.arange(len(X))\n",
    "\n",
    "# for i in indices:\n",
    "#     ax.text(X[i], Y[i], Z[i], list(titles)[i], fontsize=7)\n",
    "\n",
    "\n",
    "ax.scatter(X[indices], Y[indices], Z[indices], c=c[indices], s=s[indices], alpha=.5)\n",
    "# ax.axis(\"Off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_encodings = [np.mean([title_to_vec[v[\"title\"]] for v in videos_info_per_channel[c]], axis=0) for c in channels]\n",
    "channel_to_vec = {name: vec for name,vec in zip(channels, channel_encodings)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_channel_encodings = StandardScaler().fit_transform(channel_encodings)\n",
    "\n",
    "if reducer_type == \"PCA\":\n",
    "    # XY\n",
    "    pca = PCA(n_components=2)\n",
    "    channel_XY = pca.fit_transform(unit_channel_encodings)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.singular_values_)\n",
    "    # XYZ\n",
    "    pca = PCA(n_components=3)\n",
    "    channel_XYZ = pca.fit_transform(unit_channel_encodings)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.singular_values_)\n",
    "elif reducer_type == \"UMAP\":\n",
    "    min_dist, n_neighbors = .01, 7\n",
    "    reducer = umap.UMAP(min_dist=min_dist, n_components=2, n_neighbors=n_neighbors, verbose=True)\n",
    "    reducer.fit(unit_channel_encodings)\n",
    "    channel_XY = reducer.transform(unit_channel_encodings)\n",
    "    reducer = umap.UMAP(min_dist=min_dist, n_components=3, n_neighbors=n_neighbors, verbose=True)\n",
    "    reducer.fit(unit_channel_encodings)\n",
    "    channel_XYZ = reducer.transform(unit_channel_encodings)\n",
    "\n",
    "channel_to_xy = {k:v for k,v in zip(channel_to_vec.keys(), channel_XY)}\n",
    "channel_to_xyz = {k:v for k,v in zip(channel_to_vec.keys(), channel_XYZ)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "X = [channel_to_xy[name][0] for name in channel_to_vec]\n",
    "Y = [channel_to_xy[name][1] for name in channel_to_vec]\n",
    "\n",
    "for i, x in enumerate(X[:]):\n",
    "    ax.text(X[i], Y[i], list(channel_to_vec.keys())[i], fontsize=7)\n",
    "\n",
    "c = [np.log(channels_info[name][\"Subscribers\"]) for name in channels]\n",
    "s = [(channels_info[name][\"Subscribers\"])/50000 for name in channels]\n",
    "\n",
    "avg_views = {c: np.mean([vid[\"views\"] for vid in videos_info_per_channel[c]]) for c in channels}\n",
    "c = [np.log(avg_views[name]) for name in channels]\n",
    "s = [np.sqrt(avg_views[name])/5 for name in channels]\n",
    "\n",
    "# avg_views_per_sub = {c: avg_views[c]/channels_info[c][\"Subscribers\"] for c in channels}\n",
    "# c = [np.log(avg_views_per_sub[name]) for name in channels]\n",
    "# s = [np.sqrt(avg_views_per_sub[name])*1000 for name in channels]\n",
    "\n",
    "ax.scatter(X, Y, c=c, s=s, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6), subplot_kw=dict(projection='3d'))\n",
    "\n",
    "X = [channel_to_xyz[name][0] for name in channel_to_vec]\n",
    "Y = [channel_to_xyz[name][1] for name in channel_to_vec]\n",
    "Z = [channel_to_xyz[name][2] for name in channel_to_vec]\n",
    "\n",
    "for i, x in enumerate(X[:]):\n",
    "    ax.text(X[i], Y[i], Z[i], list(channel_to_vec.keys())[i], fontsize=7)\n",
    "\n",
    "ax.scatter(X, Y, Z, c=c, s=s, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = channels[15]\n",
    "print(\"Channel name: \", name)\n",
    "difference = (np.abs(title_encodings - channel_to_vec[name])**2).sum(-1)\n",
    "\n",
    "print(\"TITLES SORTED BY REPRESENTATIVENESS:\")\n",
    "for idx in np.argsort(difference):\n",
    "    print(titles[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
