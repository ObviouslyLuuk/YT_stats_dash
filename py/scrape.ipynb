{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium stuff\n",
    "# For a custom wait\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# For parsing and saving\n",
    "import json\n",
    "import datetime as dt\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from util.helpers import startWebdriver, get_logging_decorator\n",
    "\n",
    "from util.custom_values import DATA_DIR\n",
    "from util.constants import channel_list_URL, CHANNEL_STATS_URL, CHANNEL_URL, thumbnail_URL, ThumbnailURL, Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape list of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_channels(driver) -> list:\n",
    "    \"\"\"Scrapes channel links from url\"\"\"\n",
    "    # Css selectors\n",
    "    element_css = 'table.top-charts'\n",
    "\n",
    "    # Wait 10 seconds for the element to show up\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, element_css))\n",
    "    )\n",
    "\n",
    "    href_list = driver.execute_script(\"\"\"\n",
    "        let href_list = []; \n",
    "        document.querySelectorAll('table.top-charts')[0].querySelectorAll('tr td a').forEach((e)=>{\n",
    "            href_list.push(e.href)\n",
    "        }); \n",
    "        return href_list\n",
    "    \"\"\")\n",
    "    href_list = href_list[::2] # Skip the other link for each row\n",
    "\n",
    "    return href_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list_filepath = os.path.join(\"..\", \"data\", \"channel-list.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data\n",
    "driver = startWebdriver()\n",
    "\n",
    "with open(channel_list_filepath, \"r\") as f:\n",
    "    channel_list_by_category = json.load(f)\n",
    "\n",
    "try:\n",
    "    for cat in Topic._member_names_:\n",
    "        print(cat)\n",
    "\n",
    "        href_set = set()\n",
    "        for geography in [\"global\", \"united-states\", \"united-kingdom\", \"australia\", \"netherlands\"]:\n",
    "            url = channel_list_URL(Topic[cat], geography)\n",
    "            driver.get(url)\n",
    "\n",
    "            href_set = href_set.union(set(scrape_channels(driver)))\n",
    "\n",
    "        channel_list_by_category[cat] = [href.split('/')[3] for href in href_set]\n",
    "\n",
    "        with open(channel_list_filepath, \"w\") as f:\n",
    "            json.dump(channel_list_by_category, f)\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(channel_list_filepath, \"r\") as f:\n",
    "    channel_list_by_category = json.load(f)\n",
    "href_list_by_category = {cat: [CHANNEL_STATS_URL.format(name=name) for name in channels] for cat,channels in channel_list_by_category.items()}\n",
    "for c,l in href_list_by_category.items():\n",
    "    print(c)\n",
    "    print(l[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape info about channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_channel_info(driver) -> dict:\n",
    "    \"\"\"Scrapes channel info from link\"\"\"\n",
    "    channel_info = driver.execute_script(r\"\"\"\n",
    "        let channel_info = {}; \n",
    "        document.querySelectorAll('.box').forEach((e)=>{\n",
    "            channel_info[e.querySelector('.top-part').innerHTML] = e.querySelector('.bottom-part').innerHTML\n",
    "        }); \n",
    "        return channel_info\n",
    "    \"\"\")\n",
    "    channel_info[\"logo_url\"] = driver.execute_script(\"\"\"\n",
    "        return document.querySelector('.profile-image a img').src\n",
    "    \"\"\")\n",
    "\n",
    "    return channel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entry(entry):\n",
    "    return entry.lstrip(\"\\n \").rstrip(\"\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_channel_info(channel_info):\n",
    "    clean_channel_info = {clean_entry(k): clean_entry(v) for k,v in channel_info.items()}\n",
    "    new_channel_info = {}\n",
    "    category = clean_channel_info[\"Category\"]\n",
    "    new_channel_info[\"Category\"]    = category.split(\"/\")[2] if \"/\" in category else 'undefined'\n",
    "    country = clean_channel_info[\"Country\"]\n",
    "    new_channel_info[\"Country\"]     = country.split(\"/\")[1]  if \"/\" in country  else 'undefined'\n",
    "    new_channel_info[\"Subscribers\"] = int(clean_channel_info[\"Subscribers\"].replace(',',''))\n",
    "    new_channel_info[\"Video count\"] = int(clean_channel_info[\"Video count\"].replace(',',''))\n",
    "    new_channel_info[\"Video views\"] = int(clean_channel_info[\"Video views\"].replace(',',''))\n",
    "    new_channel_info[\"Video views\"] = int(clean_channel_info[\"Video views\"].replace(',',''))\n",
    "    new_channel_info[\"logo_url\"]    = clean_channel_info[\"logo_url\"]\n",
    "    return new_channel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = startWebdriver()\n",
    "\n",
    "try:\n",
    "    for cat in Topic._member_names_:\n",
    "        print(cat)\n",
    "\n",
    "        filepath = os.path.join(\"..\", \"data\", f\"channels-info_{cat}.json\")\n",
    "        if not os.path.isfile(filepath):\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(r\"{}\")\n",
    "\n",
    "        with open(filepath, \"r\") as f:\n",
    "            channels_info = json.load(f)\n",
    "\n",
    "        for url in tqdm(href_list_by_category[cat]):\n",
    "            channel = url.split('/')[3]\n",
    "            if channel in channels_info:\n",
    "                continue\n",
    "\n",
    "            driver.get(url)\n",
    "            time.sleep(.2)\n",
    "\n",
    "            try:\n",
    "                channel_info = scrape_channel_info(driver)\n",
    "                channels_info.update({channel: clean_channel_info(channel_info)})\n",
    "            except Exception as e:\n",
    "                print(f\"failed to scrape {channel}:\\n{e}\")\n",
    "                continue\n",
    "        \n",
    "            with open(filepath, \"w\") as f:\n",
    "                json.dump(channels_info, f)\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape info about videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_info_by_category = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", F\"channels-info_{cat}.json\"), \"r\") as f:\n",
    "        channels_info_by_category[cat] = json.load(f)\n",
    "channels_info_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_video_info(video_info):\n",
    "    return {\n",
    "        \"published\": video_info[\"publishedTimeText\"][\"simpleText\"],\n",
    "        \"title\":     video_info[\"title\"][\"runs\"][0][\"text\"],\n",
    "        \"id\":        video_info[\"videoId\"],\n",
    "        \"views\": int(video_info[\"viewCountText\"][\"simpleText\"].replace(' views','').replace(',','')),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_video_info(driver, limit=500):\n",
    "    n = 0\n",
    "    delta = 30\n",
    "    while delta >= 30 and limit <= n:\n",
    "        element_css = f'ytd-grid-video-renderer:nth-child({n+1})'\n",
    "\n",
    "        # Wait 2 seconds for the element to show up\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, element_css))\n",
    "        )\n",
    "\n",
    "        n_new = driver.execute_script(\"\"\"\n",
    "            var l = document.querySelectorAll('#dismissible'); \n",
    "                    document.querySelectorAll('#dismissible')[l.length-1].scrollIntoView(); \n",
    "            return  document.querySelectorAll('#dismissible').length\n",
    "        \"\"\")\n",
    "        delta = n_new-n\n",
    "        n = n_new\n",
    "\n",
    "    return driver.execute_script(\"\"\"\n",
    "        let data = []; \n",
    "        let l = document.querySelectorAll(\"#dismissible\");\n",
    "        l.forEach((e)=>{data.push(e.__dataHost.data)});\n",
    "        return data\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_channels_by_cat = {cat: [channel for channel,_ in sorted(channels_info_by_category[cat].items(), key=lambda x:x[1][\"Subscribers\"], reverse=True)] for cat in Topic._member_names_}\n",
    "\n",
    "interleaved_channels = []\n",
    "delta = 1\n",
    "counter = 0\n",
    "group_size = 1\n",
    "while delta > 0:\n",
    "    len_before = len(interleaved_channels)\n",
    "    for cat in Topic._member_names_:\n",
    "        for i in range(group_size):\n",
    "            idx = counter + i\n",
    "            channel_list = sorted_channels_by_cat[cat]\n",
    "            if idx >= len(channel_list):\n",
    "                continue\n",
    "\n",
    "            interleaved_channels.append((cat, channel_list[idx]))\n",
    "    delta = len(interleaved_channels) - len_before\n",
    "    counter += group_size\n",
    "interleaved_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = startWebdriver(headless=False)\n",
    "\n",
    "name2id_filepath = os.path.join(\"..\", \"data\", \"channel_name2id.json\")\n",
    "with open(name2id_filepath, \"r\") as f:\n",
    "    name2id = json.load(f)\n",
    "\n",
    "videos_info_by_category = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", f\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        videos_info_by_category[cat].update(json.load(f))\n",
    "\n",
    "try:\n",
    "    for cat,channel in tqdm(interleaved_channels):\n",
    "        videos_info = videos_info_by_category[cat]\n",
    "        if channel in videos_info and channel in name2id:\n",
    "            continue\n",
    "        elif channel in name2id:\n",
    "            yt_url = f\"https://www.youtube.com/channel/{name2id[channel]}\"\n",
    "        else:\n",
    "            relay_url = CHANNEL_URL.format(name=channel)\n",
    "\n",
    "            driver.get(relay_url)\n",
    "            name2id.update({channel: driver.current_url.split(\"/\")[4]})\n",
    "            yt_url = driver.current_url\n",
    "\n",
    "        if channel in videos_info:\n",
    "            continue\n",
    "        driver.get(yt_url+\"/videos\")\n",
    "\n",
    "        try:\n",
    "            raw_videos_info = scrape_video_info(driver, 30)\n",
    "            clean_videos_info = [clean_video_info(vid_info) for vid_info in raw_videos_info]\n",
    "            videos_info_by_category[cat][channel] = clean_videos_info\n",
    "        except Exception as e:\n",
    "            print(f\"failed to scrape {channel}:\\n{e}\")\n",
    "            continue\n",
    "        \n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name2id_filepath, \"w\") as f:\n",
    "    json.dump(name2id, f)\n",
    "\n",
    "for cat in Topic._member_names_:\n",
    "    videos_info = {c:v for c,v in videos_info_by_category[cat].items() if len(v) >= 30}\n",
    "\n",
    "    with open(os.path.join(\"..\", \"data\", f\"videos-info_{cat}.json\"), \"w\") as f:\n",
    "        json.dump(videos_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_info_by_category = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        videos_info_by_category[cat] = json.load(f)\n",
    "videos_info_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in Topic._member_names_:\n",
    "    print(cat)\n",
    "\n",
    "    for channel_name in tqdm(videos_info_by_category[cat]):\n",
    "        for video_info in videos_info[channel_name]:\n",
    "            id = video_info[\"id\"]\n",
    "            quality = ThumbnailURL.high\n",
    "            url = thumbnail_URL(id, quality)\n",
    "\n",
    "            filepath = os.path.join(\"..\", \"data\", \"thumbnails\", f\"{id}_{quality.name}.jpg\")\n",
    "            if os.path.isfile(filepath):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "            except HTTPError:\n",
    "                print(f\"couldn't fetch {id} by {channel_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
