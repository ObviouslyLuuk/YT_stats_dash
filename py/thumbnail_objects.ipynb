{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sila\\anaconda3\\envs\\MulAnal\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from util.constants import Topic\n",
    "\n",
    "from transformers import YolosFeatureExtractor, YolosForObjectDetection\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"coco_classes.txt\"), \"r\") as f:\n",
    "    coco_classes = [c.rstrip(\"\\n\") for c in f.readlines()]\n",
    "coco_classes.insert(0, \"unknown\")\n",
    "\n",
    "feature_extractor = YolosFeatureExtractor.from_pretrained(\"hustvl/yolos-small\")\n",
    "YOLOS_model = YolosForObjectDetection.from_pretrained(\"hustvl/yolos-small\")\n",
    "\n",
    "def model(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    inputs = feature_extractor(images=img, return_tensors=\"pt\")\n",
    "    outputs = YOLOS_model(**inputs)\n",
    "    l = []\n",
    "\n",
    "    # model predicts bounding boxes and corresponding COCO classes\n",
    "    logits = outputs.logits\n",
    "    bboxes = outputs.pred_boxes\n",
    "\n",
    "    probs = F.softmax(logits.detach().clone(), dim=-1)  # [B, 100, 92]\n",
    "    preds      = probs.argmax(-1) # [B, 100]\n",
    "    confidence = probs.max(-1)[0] # [B, 100]\n",
    "    known_indices     = [(preds_img != 91).nonzero()[:,0] for preds_img in preds] # [B, known indices]\n",
    "    confident_indices = [(conf_img > 0.75).nonzero()[:,0] for conf_img in confidence] # [B, confident indices]\n",
    "    indices = [list(set(known_idx_img.tolist()).intersection(set(conf_idx_img.tolist()))) for known_idx_img,conf_idx_img in zip(known_indices, confident_indices)] # [B, intersection of indices]\n",
    "    pred_classes = [[coco_classes[v] for v in preds_img[idx_img]] for preds_img, idx_img in zip(preds, indices)] # [B, predicted classes]\n",
    "\n",
    "    confidence = (confidence*100).tolist()\n",
    "\n",
    "    pred_boxes = bboxes.detach().clone()\n",
    "    cmap = plt.cm.get_cmap(\"hsv\", len(coco_classes))\n",
    "\n",
    "    for j, patch_idx in enumerate(indices[0]):\n",
    "        c = pred_classes[0][j]\n",
    "        conf = confidence[0][patch_idx]\n",
    "        bbox = pred_boxes[0, patch_idx].detach()\n",
    "        x, y, W, H = bbox.split(1)\n",
    "        im_w = img.width\n",
    "        im_h = img.height\n",
    "        W *= im_w\n",
    "        H *= im_h\n",
    "        x = x*im_w - W*.5\n",
    "        y = y*im_h - H*.5\n",
    "\n",
    "        # Create a Rectangle patch\n",
    "        color = cmap(preds[0][patch_idx].item())\n",
    "        # color = \"b\"\n",
    "        rect = patches.Rectangle((x, y), W, H, linewidth=2,\n",
    "            edgecolor=color,\n",
    "            facecolor='none',\n",
    "        )\n",
    "        x = {\"pred_class\": c,\n",
    "            \"conf\": conf,\n",
    "            \"bbox\": bbox.tolist()}\n",
    "        l.append(x)\n",
    "    \n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latents for all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "videos = []\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        videos_info = json.load(f)\n",
    "        videos.extend([vid for channel_vids in videos_info.values() for vid in channel_vids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(\"..\", \"data\", \"thumbnails-object\")\n",
    "\n",
    "video_results_dir = os.path.join(RESULTS_DIR, \"videos\")\n",
    "channel_results_dir = os.path.join(RESULTS_DIR, \"channels\")\n",
    "def get_done_list(dir):\n",
    "    return [nm.replace(\".json\",'') for nm in os.listdir(dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 722429/722429 [01:21<00:00, 8840.59it/s] \n"
     ]
    }
   ],
   "source": [
    "# Calculate video results\n",
    "vid2result = {}\n",
    "done_list = get_done_list(video_results_dir)\n",
    "for vid in tqdm(videos):\n",
    "    id = vid[\"id\"]\n",
    "    if id in done_list:\n",
    "        continue\n",
    "    img_path = \"../data/thumbnails/\"+id+\"_high.jpg\"\n",
    "    if os.path.isfile(img_path):\n",
    "        vid2result[id] = model(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save video results\n",
    "for vid_id,result in vid2result.items():\n",
    "    #print(vid_id)\n",
    "    #print(result)\n",
    "    path = os.path.join(video_results_dir, f\"{vid_id}.json\")\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"vid2channel.json\"), \"r\") as f:\n",
    "    vid2channel = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 260.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make list of results per video for each channel\n",
    "channel_result_list = defaultdict(list)\n",
    "for vid_id in tqdm(get_done_list(video_results_dir)):\n",
    "    channel = vid2channel[vid_id]\n",
    "    filepath = os.path.join(video_results_dir, f\"{vid_id}.json\")\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            result = json.load(f)\n",
    "    except JSONDecodeError:\n",
    "        print(f\"couldn't open {vid_id}; deleting file\")\n",
    "        os.remove(filepath)\n",
    "    channel_result_list[channel].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Works till here then it needs the inverted lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'pred_class': 'person', 'conf': 99.86813354492188, 'bbox': [0.16978369653224945, 0.5443723201751709, 162.1193389892578, 240.9904327392578]}\n",
      "  {'pred_class': 'person', 'conf': 99.9327392578125, 'bbox': [0.5046120882034302, 0.5368502140045166, 155.4878387451172, 243.84986877441406]}\n",
      "  {'pred_class': 'cell phone', 'conf': 86.10973358154297, 'bbox': [0.4223462641239166, 0.7047587633132935, 43.598812103271484, 67.23351287841797]}\n",
      "  {'pred_class': 'toothbrush', 'conf': 76.47359466552734, 'bbox': [0.0462351031601429, 0.7307983636856079, 14.49171257019043, 55.052001953125]}\n",
      "  {'pred_class': 'person', 'conf': 99.68734741210938, 'bbox': [0.8342981338500977, 0.5453698635101318, 158.6527099609375, 241.33522033691406]}]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sila\\Documents\\GitHub\\YT_stats_dash\\py\\thumbnail_objects.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=3'>4</a>\u001b[0m result_list \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(result_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=5'>6</a>\u001b[0m channel_results[channel] \u001b[39m=\u001b[39m {\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m: result_list\u001b[39m.\u001b[39;49mmean(axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m\"\u001b[39m: result_list\u001b[39m.\u001b[39mstd(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlen\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlen\u001b[39m(result_list),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sila/Documents/GitHub/YT_stats_dash/py/thumbnail_objects.ipynb#ch0000010?line=9'>10</a>\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Sila\\anaconda3\\envs\\MulAnal\\lib\\site-packages\\numpy\\core\\_methods.py:182\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Sila/anaconda3/envs/MulAnal/lib/site-packages/numpy/core/_methods.py?line=179'>180</a>\u001b[0m ret \u001b[39m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39mwhere)\n\u001b[0;32m    <a href='file:///c%3A/Users/Sila/anaconda3/envs/MulAnal/lib/site-packages/numpy/core/_methods.py?line=180'>181</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Sila/anaconda3/envs/MulAnal/lib/site-packages/numpy/core/_methods.py?line=181'>182</a>\u001b[0m     ret \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39;49mtrue_divide(\n\u001b[0;32m    <a href='file:///c%3A/Users/Sila/anaconda3/envs/MulAnal/lib/site-packages/numpy/core/_methods.py?line=182'>183</a>\u001b[0m             ret, rcount, out\u001b[39m=\u001b[39;49mret, casting\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39munsafe\u001b[39;49m\u001b[39m'\u001b[39;49m, subok\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Sila/anaconda3/envs/MulAnal/lib/site-packages/numpy/core/_methods.py?line=183'>184</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_float16_result \u001b[39mand\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Sila/anaconda3/envs/MulAnal/lib/site-packages/numpy/core/_methods.py?line=184'>185</a>\u001b[0m         ret \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype(ret)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "# Calculate channel results\n",
    "channel_results = {}\n",
    "for channel,result_list in channel_result_list.items():\n",
    "    result_list = np.array(result_list)\n",
    "    print(result_list)\n",
    "    channel_results[channel] = {\n",
    "        \"mean\": result_list.mean(axis=0),\n",
    "        \"std\": result_list.std(),\n",
    "        \"len\": len(result_list),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save channel stats\n",
    "for channel,results in channel_results.items():\n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"channel2category.json\"), \"r\") as f:\n",
    "    channel2cat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of results per channel for each category\n",
    "category_results_list = defaultdict(list)\n",
    "for channel in tqdm(get_done_list(channel_results_dir)):\n",
    "    cat = channel2cat[channel]\n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    except JSONDecodeError:\n",
    "        print(f\"couldn't open {channel}; deleting file\")\n",
    "        os.remove(filepath)\n",
    "    category_results_list[cat].append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category results\n",
    "category_results = {}\n",
    "for cat,stats_list in category_results_list.items():\n",
    "    mean_list = np.array([channel_stats[\"mean\"] for channel_stats in stats_list])\n",
    "    std_list = np.array([channel_stats[\"std\"] for channel_stats in stats_list])\n",
    "    category_results[cat] = {\n",
    "        \"mean\": mean_list.mean(axis=0).tolist(),\n",
    "        \"std\": std_list.mean(),\n",
    "        \"len\": len(mean_list),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save category results\n",
    "for cat,stats in category_results.items():\n",
    "    filepath = os.path.join(\"..\", \"data\", \"title-latents\", \"categories\", f\"{cat}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(stats, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92b2e1a3a28228dcac82ad11eb85c5b8311b8e0cf10b3df56d24e9ab756450cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('MulAnal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
