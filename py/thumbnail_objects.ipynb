{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from util.constants import Topic, ThumbnailURL, thumbnail_URL\n",
    "import requests\n",
    "\n",
    "from transformers import YolosFeatureExtractor, YolosForObjectDetection\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"coco_classes.txt\"), \"r\") as f:\n",
    "    coco_classes = [c.rstrip(\"\\n\") for c in f.readlines()]\n",
    "coco_classes.insert(0, \"unknown\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "feature_extractor = YolosFeatureExtractor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "def load_model():\n",
    "    return YolosForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\").to(device)\n",
    "YOLOS_model = load_model()\n",
    "\n",
    "# Print model size\n",
    "mem_params = sum([param.nelement()*param.element_size() for param in YOLOS_model.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in YOLOS_model.buffers()])\n",
    "print(f\"Memory used by model: {mem_params + mem_bufs} bytes\")\n",
    "\n",
    "\n",
    "def model(images):\n",
    "    inputs = feature_extractor(images=images, return_tensors=\"pt\").to(device)\n",
    "    outputs = YOLOS_model(**inputs)\n",
    "\n",
    "    ls = np.zeros((len(images),0)).tolist()\n",
    "\n",
    "    # model predicts bounding boxes and corresponding COCO classes\n",
    "    logits = outputs.logits.detach().cpu()\n",
    "    bboxes = outputs.pred_boxes.detach().cpu()\n",
    "\n",
    "    probs = F.softmax(logits.clone(), dim=-1)  # [B, 100, 92]\n",
    "    preds      = probs.argmax(-1) # [B, 100]\n",
    "    confidence = probs.max(-1)[0] # [B, 100]\n",
    "    known_indices     = [(preds_img != 91).nonzero()[:,0] for preds_img in preds] # [B, known indices]\n",
    "    confident_indices = [(conf_img > 0.75).nonzero()[:,0] for conf_img in confidence] # [B, confident indices]\n",
    "    indices = [list(set(known_idx_img.tolist()).intersection(set(conf_idx_img.tolist()))) for known_idx_img,conf_idx_img in zip(known_indices, confident_indices)] # [B, intersection of indices]\n",
    "    pred_classes = [[coco_classes[v] for v in preds_img[idx_img]] for preds_img, idx_img in zip(preds, indices)] # [B, predicted classes]\n",
    "\n",
    "    confidence = np.round((confidence*100).tolist(), 1)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        for j, patch_idx in enumerate(indices[i]):\n",
    "            c = pred_classes[i][j]\n",
    "            conf = confidence[i][patch_idx]\n",
    "            bbox = np.round(bboxes[i, patch_idx].tolist(), 3).tolist()\n",
    "\n",
    "            ls[i].append({\n",
    "                \"pred_class\": c,\n",
    "                \"conf\": conf,\n",
    "                \"bbox\": bbox\n",
    "            })\n",
    "    \n",
    "    return ls\n",
    "\n",
    "def resize(img, new_width=100):\n",
    "    wpercent = (new_width/float(img.size[0]))\n",
    "    hsize = int((float(img.size[1])*float(wpercent)))\n",
    "    return img.resize((new_width,hsize), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get objects for all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "videos = []\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        videos_info = json.load(f)\n",
    "        videos.extend([vid for channel_vids in videos_info.values() for vid in channel_vids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(\"..\", \"data\", \"thumbnail-objects\")\n",
    "\n",
    "video_results_dir = os.path.join(RESULTS_DIR, \"videos\")\n",
    "channel_results_dir = os.path.join(RESULTS_DIR, \"channels\")\n",
    "def get_done_list(dir):\n",
    "    return [nm.replace(\".json\",'') for nm in os.listdir(dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del YOLOS_model\n",
    "torch.cuda.memory_allocated() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del YOLOS_model\n",
    "except:\n",
    "    YOLOS_model = load_model()\n",
    "torch.cuda.memory_allocated() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code in batches\n",
    "batch_size = 4\n",
    "batch_num = len(videos)//batch_size\n",
    "if batch_num != int(len(videos)/batch_size):\n",
    "    batch_num += 1 \n",
    "\n",
    "quality = ThumbnailURL.high\n",
    "\n",
    "done_list = get_done_list(video_results_dir)\n",
    "for batch in tqdm(range(batch_num)):\n",
    "\n",
    "    vid_batch = videos[batch*batch_size:(batch+1)*batch_size]\n",
    "\n",
    "    ids = [vid[\"id\"] for vid in vid_batch if\n",
    "        # os.path.isfile(\"../data/thumbnails/\"+vid[\"id\"]+\"_high.jpg\") and\n",
    "        vid[\"id\"] not in done_list]\n",
    "\n",
    "    if not ids:\n",
    "        continue\n",
    "\n",
    "    # imgs_paths = [\"../data/thumbnails/\"+vid_id+\"_high.jpg\" for vid_id in ids]\n",
    "    # images = [Image.open(path) for path in imgs_paths]\n",
    "\n",
    "    raws = []\n",
    "    fetched_ids = []\n",
    "    for id in ids:\n",
    "        url = thumbnail_URL(id, quality)\n",
    "        try:\n",
    "            raws.append(requests.get(url, stream=True).raw)\n",
    "        except:\n",
    "            continue\n",
    "        fetched_ids.append(id)\n",
    "    images = [Image.open(raw) for raw in raws]\n",
    "    ids = fetched_ids\n",
    "\n",
    "    # images = [resize(img, 100) for img in images]\n",
    "\n",
    "    results = model(images)\n",
    "\n",
    "    for vid_id, result in zip(ids, results):\n",
    "        path = os.path.join(video_results_dir, f\"{vid_id}.json\")\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"vid2channel.json\"), \"r\") as f:\n",
    "    vid2channel = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of results per video for each channel\n",
    "channel_result_list = defaultdict(list)\n",
    "for vid_id in tqdm(get_done_list(video_results_dir)):\n",
    "    channel = vid2channel[vid_id]\n",
    "    filepath = os.path.join(video_results_dir, f\"{vid_id}.json\")\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            result = json.load(f)\n",
    "    except JSONDecodeError:\n",
    "        print(f\"couldn't open {vid_id}; deleting file\")\n",
    "        os.remove(filepath)\n",
    "    channel_result_list[channel].append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Works till here then it needs the inverted lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate channel results\n",
    "channel_results = {}\n",
    "for channel,result_list in channel_result_list.items():\n",
    "    result_list = np.array(result_list)\n",
    "    print(result_list)\n",
    "    channel_results[channel] = {\n",
    "        \"mean\": result_list.mean(axis=0),\n",
    "        \"std\": result_list.std(),\n",
    "        \"len\": len(result_list),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save channel stats\n",
    "for channel,results in channel_results.items():\n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"channel2category.json\"), \"r\") as f:\n",
    "    channel2cat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of results per channel for each category\n",
    "category_results_list = defaultdict(list)\n",
    "for channel in tqdm(get_done_list(channel_results_dir)):\n",
    "    cat = channel2cat[channel]\n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    except JSONDecodeError:\n",
    "        print(f\"couldn't open {channel}; deleting file\")\n",
    "        os.remove(filepath)\n",
    "    category_results_list[cat].append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category results\n",
    "category_results = {}\n",
    "for cat,stats_list in category_results_list.items():\n",
    "    mean_list = np.array([channel_stats[\"mean\"] for channel_stats in stats_list])\n",
    "    std_list = np.array([channel_stats[\"std\"] for channel_stats in stats_list])\n",
    "    category_results[cat] = {\n",
    "        \"mean\": mean_list.mean(axis=0).tolist(),\n",
    "        \"std\": std_list.mean(),\n",
    "        \"len\": len(mean_list),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save category results\n",
    "for cat,stats in category_results.items():\n",
    "    filepath = os.path.join(\"..\", \"data\", \"title-latents\", \"categories\", f\"{cat}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
