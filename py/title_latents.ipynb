{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from util.constants import Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens').to(device)\n",
    "\n",
    "def model(titles):\n",
    "    return sbert_model.encode(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latents for all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "videos = []\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        videos_info = json.load(f)\n",
    "        videos.extend([vid for channel_vids in videos_info.values() for vid in channel_vids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(\"..\", \"data\", \"title-latents\")\n",
    "\n",
    "video_results_dir = os.path.join(\"..\",\"..\",\"DATA\",\"title-latents\",\"videos\")\n",
    "channel_results_dir = os.path.join(RESULTS_DIR, \"channels\")\n",
    "\n",
    "if not os.path.exists(video_results_dir):\n",
    "    os.makedirs(video_results_dir)\n",
    "\n",
    "def get_done_list(dir):\n",
    "    return [nm.replace(\".json\",'').replace('.pt','') for nm in os.listdir(dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code in batches\n",
    "done_list = get_done_list(video_results_dir)\n",
    "vid2title = {v[\"id\"]:v[\"title\"] for v in videos}\n",
    "all_ids = [vid[\"id\"] for vid in tqdm(videos)]\n",
    "todo_ids = list(set(all_ids).difference(done_list))\n",
    "\n",
    "batch_size = 512\n",
    "batch_num = len(todo_ids)//batch_size\n",
    "if batch_num != int(len(todo_ids)/batch_size):\n",
    "    batch_num += 1\n",
    "\n",
    "for batch in tqdm(range(batch_num)):\n",
    "    ids = todo_ids[batch*batch_size:(batch+1)*batch_size]\n",
    "    titles = [vid2title[id] for id in ids]\n",
    "\n",
    "    batch_latents = model(titles)\n",
    "\n",
    "    for vid_id, result in zip(ids, batch_latents):\n",
    "        path = os.path.join(video_results_dir, f\"{vid_id}.pt\")\n",
    "        torch.save(result, path)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "channel_videos_dict = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        channel_videos_dict.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate channel results\n",
    "done_list = get_done_list(video_results_dir)\n",
    "for channel,videos in tqdm(channel_videos_dict.items()):\n",
    "    result_list = []\n",
    "    for vid in videos:\n",
    "        vid_id = vid[\"id\"]\n",
    "        filepath = os.path.join(video_results_dir, vid_id+\".pt\")\n",
    "        try:\n",
    "            result_list.append(torch.load(filepath))\n",
    "        except JSONDecodeError:\n",
    "            print(f\"couldn't open {vid_id}; deleting file\")\n",
    "            os.remove(filepath)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"couldn't find {vid_id}\")\n",
    "\n",
    "    result_list = np.array(result_list)\n",
    "    channel_mean = result_list.mean(axis=0)\n",
    "    channel_result = {\n",
    "        \"std\": float(result_list.std()),\n",
    "        \"len\": len(result_list),\n",
    "    }\n",
    "\n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(channel_result, f)\n",
    "    filepath = os.path.join(RESULTS_DIR, \"channels_mean\", f\"{channel}.pt\")\n",
    "    torch.save(channel_mean, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"channel2category.json\"), \"r\") as f:\n",
    "    channel2cat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of results per channel for each category\n",
    "category_results_list = defaultdict(list)\n",
    "for channel in tqdm(get_done_list(channel_results_dir)):\n",
    "    cat = channel2cat[channel]\n",
    "    results = {}\n",
    "    for folder,ext in [(\"channels\",\".json\"), (\"channels_mean\",\".pt\")]:\n",
    "        filepath = os.path.join(RESULTS_DIR, folder, channel+ext)\n",
    "        try:\n",
    "            if ext == \".json\":\n",
    "                with open(filepath, \"r\") as f:\n",
    "                    results.update(json.load(f))\n",
    "            elif ext == \".pt\":\n",
    "                results.update({\"mean\": torch.load(filepath)})\n",
    "        except JSONDecodeError:\n",
    "            print(f\"couldn't open {channel}; deleting file\")\n",
    "            os.remove(filepath)\n",
    "    category_results_list[cat].append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category results\n",
    "for cat,stats_list in category_results_list.items():\n",
    "    mean_list = np.array([channel_stats[\"mean\"] for channel_stats in stats_list])\n",
    "    std_list = np.array([channel_stats[\"std\"] for channel_stats in stats_list])\n",
    "    category_mean = mean_list.mean(axis=0)\n",
    "    category_result = {\n",
    "        \"std\": std_list.mean(),\n",
    "        \"len\": len(mean_list),\n",
    "    }\n",
    "\n",
    "    filepath = os.path.join(RESULTS_DIR, \"categories\", f\"{cat}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(category_result, f)\n",
    "    filepath = os.path.join(RESULTS_DIR, \"categories_mean\", f\"{cat}.pt\")\n",
    "    torch.save(category_mean, filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
