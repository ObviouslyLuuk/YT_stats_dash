{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from util.constants import Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens').to(device)\n",
    "\n",
    "def model(titles):\n",
    "    return sbert_model.encode(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latents for all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "channel_videos_dict = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        channel_videos_dict.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(\"..\", \"data\", \"title-latents\")\n",
    "\n",
    "video_results_dir = os.path.join(\"..\",\"..\",\"DATA\",\"title-latents\",\"videos\")\n",
    "channel_results_dir = os.path.join(RESULTS_DIR, \"channels\")\n",
    "\n",
    "if not os.path.exists(video_results_dir):\n",
    "    os.makedirs(video_results_dir)\n",
    "\n",
    "def get_done_list(dir):\n",
    "    return [nm.replace(\".json\",'').replace('.pt','') for nm in os.listdir(dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code in batches\n",
    "for channel,videos in tqdm(channel_videos_dict.items()):\n",
    "    done_path = os.path.join(RESULTS_DIR, \"videos_done\", channel+\".json\")\n",
    "    ids = [vid[\"id\"] for vid in videos[:30]]\n",
    "    try:\n",
    "        with open(done_path, \"r\") as f:\n",
    "            done_ids = json.load(f)\n",
    "        if set(ids).issubset(done_ids): # Every id is done\n",
    "            continue\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    titles = [vid[\"title\"] for vid in videos[:30]]\n",
    "    \n",
    "    batch_latents = np.array(model(titles))\n",
    "\n",
    "    path = os.path.join(video_results_dir, f\"{channel}.pt\")\n",
    "    torch.save(batch_latents, path)\n",
    "    with open(done_path, \"w\") as f:\n",
    "        json.dump(ids, f)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "channel_videos_dict = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        channel_videos_dict.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate channel results\n",
    "for channel,videos in tqdm(channel_videos_dict.items()):\n",
    "    in_path = os.path.join(video_results_dir,channel+\".pt\")\n",
    "    result_list = torch.load(in_path)\n",
    "\n",
    "    channel_mean = result_list.mean(axis=0)\n",
    "    channel_result = {\n",
    "        \"std\": float(result_list.std()),\n",
    "        \"len\": len(result_list),\n",
    "    }\n",
    "\n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(channel_result, f)\n",
    "    filepath = os.path.join(RESULTS_DIR, \"channels_mean\", f\"{channel}.pt\")\n",
    "    torch.save(channel_mean, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"channel2category.json\"), \"r\") as f:\n",
    "    channel2cat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of results per channel for each category\n",
    "category_results_list = defaultdict(list)\n",
    "for channel in tqdm(get_done_list(channel_results_dir)):\n",
    "    cat = channel2cat[channel]\n",
    "    results = {}\n",
    "    for folder,ext in [(\"channels\",\".json\"), (\"channels_mean\",\".pt\")]:\n",
    "        filepath = os.path.join(RESULTS_DIR, folder, channel+ext)\n",
    "        try:\n",
    "            if ext == \".json\":\n",
    "                with open(filepath, \"r\") as f:\n",
    "                    results.update(json.load(f))\n",
    "            elif ext == \".pt\":\n",
    "                results.update({\"mean\": torch.load(filepath)})\n",
    "        except JSONDecodeError:\n",
    "            print(f\"couldn't open {channel}; deleting file\")\n",
    "            os.remove(filepath)\n",
    "    category_results_list[cat].append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category results\n",
    "for cat,stats_list in category_results_list.items():\n",
    "    mean_list = np.array([channel_stats[\"mean\"] for channel_stats in stats_list])\n",
    "    std_list = np.array([channel_stats[\"std\"] for channel_stats in stats_list])\n",
    "    category_mean = mean_list.mean(axis=0)\n",
    "    category_result = {\n",
    "        \"std\": float(mean_list.std()),\n",
    "        \"avg_std_of_channels\": std_list.mean(),\n",
    "        \"len\": len(mean_list),\n",
    "    }\n",
    "\n",
    "    filepath = os.path.join(RESULTS_DIR, \"categories\", f\"{cat}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(category_result, f)\n",
    "    filepath = os.path.join(RESULTS_DIR, \"categories_mean\", f\"{cat}.pt\")\n",
    "    torch.save(category_mean, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
