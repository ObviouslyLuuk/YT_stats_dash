{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from util.constants import Topic\n",
    "from util.helpers import extend_dicts, sort_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "channel_videos_dict = {}\n",
    "for cat in Topic._member_names_:\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        channel_videos_dict.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(\"..\", \"data\", \"title-tokens\")\n",
    "\n",
    "channel_results_dir = os.path.join(RESULTS_DIR, \"channels\")\n",
    "def get_done_list(dir):\n",
    "    return [nm.replace(\".json\",'') for nm in os.listdir(dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make channel inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index\n",
    "for channel,videos in tqdm(channel_videos_dict.items()):\n",
    "    inv_idx = defaultdict(list)\n",
    "    for vid in videos:\n",
    "        tokens = nltk.word_tokenize(vid[\"title\"])\n",
    "        for t in set(tokens):\n",
    "            inv_idx[t].append(vid[\"id\"])\n",
    "    with open(os.path.join(RESULTS_DIR, \"channels_inv_index\", f\"{channel}.json\"), \"w\") as f:\n",
    "        json.dump(inv_idx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate channel results\n",
    "for channel,videos in tqdm(channel_videos_dict.items()):\n",
    "    video_info_dict = {vid[\"id\"]:vid for vid in videos}\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"channels_inv_index\", f\"{channel}.json\"), \"r\") as f:\n",
    "        inv_idx = json.load(f)\n",
    "\n",
    "    channel_result = {\n",
    "        \"token_views\": sort_dict({k:sum([video_info_dict[id][\"views\"] for id in v]) for k,v in inv_idx.items()}),\n",
    "        \"token_counts\": sort_dict({k:len(v) for k,v in inv_idx.items()}),\n",
    "    }\n",
    "    \n",
    "    filepath = os.path.join(channel_results_dir, f\"{channel}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(channel_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(os.path.join(\"..\", \"data\", \"channel2category.json\"), \"r\") as f:\n",
    "    channel2cat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of channels for each category\n",
    "category_channels_dict = {}\n",
    "for cat in tqdm(Topic._member_names_):\n",
    "    with open(os.path.join(\"..\", \"data\", \"info_videos\", F\"videos-info_{cat}.json\"), \"r\") as f:\n",
    "        category_channels_dict[cat] = list(json.load(f).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index\n",
    "for cat,channels in category_channels_dict.items():\n",
    "    print(cat)\n",
    "    \n",
    "    inv_indices = []\n",
    "    for channel in tqdm(channels):\n",
    "        with open(os.path.join(RESULTS_DIR, \"channels_inv_index\", f\"{channel}.json\"), \"r\") as f:\n",
    "            inv_indices.append(json.load(f))\n",
    "\n",
    "    inv_idx = extend_dicts(inv_indices)\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"categories_inv_index\", f\"{cat}.json\"), \"w\") as f:\n",
    "        json.dump(inv_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate category results\n",
    "for cat,channels in tqdm(category_channels_dict.items()):\n",
    "    video_info_dict = {vid[\"id\"]:vid for channel in channels for vid in channel_videos_dict[channel]}\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"categories_inv_index\", f\"{cat}.json\"), \"r\") as f:\n",
    "        inv_idx = json.load(f)\n",
    "\n",
    "    category_result = {\n",
    "        \"token_views\": sort_dict({k:sum([video_info_dict[id][\"views\"] for id in v]) for k,v in inv_idx.items()}),\n",
    "        \"token_counts\": sort_dict({k:len(v) for k,v in inv_idx.items()}),\n",
    "    }\n",
    "    \n",
    "    filepath = os.path.join(RESULTS_DIR, \"categories\", f\"{cat}.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(category_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF*IDF for channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Frequency\n",
    "for cat,channels in category_channels_dict.items():\n",
    "    print(cat)\n",
    "\n",
    "    df = defaultdict(int)\n",
    "    for channel in tqdm(channels):\n",
    "        with open(os.path.join(RESULTS_DIR, \"channels_inv_index\", f\"{channel}.json\"), \"r\") as f:\n",
    "            inv_idx = json.load(f)\n",
    "        for token in inv_idx:\n",
    "            df[token] += 1\n",
    "\n",
    "    df = sort_dict(df)\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"categories_doc_freq\", f\"{cat}.json\"), \"w\") as f:\n",
    "        json.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf*idf\n",
    "for cat,channels in category_channels_dict.items():\n",
    "    print(cat)\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"categories_doc_freq\", f\"{cat}.json\"), \"r\") as f:\n",
    "        df = json.load(f)\n",
    "    idf = {k:np.log(len(channels)/v) for k,v in df.items()}\n",
    "\n",
    "    for channel in tqdm(channels):\n",
    "        with open(os.path.join(RESULTS_DIR, \"channels\", f\"{channel}.json\"), \"r\") as f:\n",
    "            tf = json.load(f)[\"token_counts\"]\n",
    "\n",
    "        terms = list(tf.keys())\n",
    "        freqs = np.array(list(tf.values()))\n",
    "        channel_idf = np.array([idf[k] for k in tf])\n",
    "\n",
    "        tf_idf = freqs*channel_idf\n",
    "        tf_idf = {term:freq for term,freq in zip(terms,tf_idf)}\n",
    "\n",
    "        tf_idf = sort_dict(tf_idf)\n",
    "\n",
    "        with open(os.path.join(RESULTS_DIR, \"channels_tf_idf\", f\"{channel}.json\"), \"w\") as f:\n",
    "            json.dump(tf_idf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF*IDF for categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Frequency\n",
    "df = defaultdict(int)\n",
    "for cat,channels in category_channels_dict.items():\n",
    "    print(cat)\n",
    "\n",
    "    for channel in tqdm(channels):\n",
    "        with open(os.path.join(RESULTS_DIR, \"channels_inv_index\", f\"{channel}.json\"), \"r\") as f:\n",
    "            inv_idx = json.load(f)\n",
    "        for token in inv_idx:\n",
    "            df[token] += 1\n",
    "\n",
    "df = sort_dict(df)\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, f\"doc_freq_all.json\"), \"w\") as f:\n",
    "    json.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf*idf\n",
    "with open(os.path.join(RESULTS_DIR, f\"doc_freq_all.json\"), \"r\") as f:\n",
    "    df = json.load(f)\n",
    "idf = {k:np.log(len(channel2cat)/v) for k,v in df.items()}\n",
    "\n",
    "for cat,channels in category_channels_dict.items():\n",
    "    print(cat)\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"categories\", f\"{cat}.json\"), \"r\") as f:\n",
    "        tf = json.load(f)[\"token_counts\"]\n",
    "\n",
    "    terms = list(tf.keys())\n",
    "    freqs = np.array(list(tf.values()))\n",
    "    cat_idf = np.array([idf[k] for k in tf])\n",
    "\n",
    "    tf_idf = freqs*cat_idf\n",
    "    tf_idf = {term:freq for term,freq in zip(terms,tf_idf)}\n",
    "\n",
    "    tf_idf = sort_dict(tf_idf)\n",
    "\n",
    "    with open(os.path.join(RESULTS_DIR, \"categories_tf_idf\", f\"{cat}.json\"), \"w\") as f:\n",
    "        json.dump(tf_idf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
